{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "Today we're going to experiment with feature selection. We will create a few different models and see if we can improve/maintain the same performance with a subset of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "# Vi kan se att vi har ett dataset med 1000 rader, 10 kolumner, 5 av våra features\n",
    "# är kassa, 5 är bra\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=42)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05935747, -0.81075922, -1.46291185, ..., -0.71333492,\n",
       "        -0.38779067,  0.30975536],\n",
       "       [ 1.35040799,  4.22073174,  1.56416182, ..., -1.35261676,\n",
       "         0.56164546,  3.05553349],\n",
       "       [ 1.06995768,  3.02959431, -2.68448393, ...,  1.67460575,\n",
       "         1.4897756 ,  0.03734801],\n",
       "       ...,\n",
       "       [ 1.32117879,  3.00727694,  0.242322  , ..., -0.802865  ,\n",
       "         0.67092995,  2.27887143],\n",
       "       [-0.52716176,  0.70840414, -1.69716553, ..., -0.58513067,\n",
       "        -0.57348277, -0.17506291],\n",
       "       [-1.72169116, -0.78642113, -1.12858852, ...,  2.46859264,\n",
       "        -0.00922643, -2.81226403]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with a random forest model, here we can evaluate \n",
    "# the importance of each feature in the model \n",
    "# with the feature_importances_ attribute\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf  = RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importance = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04150628 0.09891617 0.0603883  0.27042094 0.12803106 0.07157635\n",
      " 0.07179852 0.1318597  0.04484533 0.08065736]\n"
     ]
    }
   ],
   "source": [
    "# Inspect feature importance\n",
    "\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.04151\n",
      "Feature: 1, Score: 0.09892\n",
      "Feature: 2, Score: 0.06039\n",
      "Feature: 3, Score: 0.27042\n",
      "Feature: 4, Score: 0.12803\n",
      "Feature: 5, Score: 0.07158\n",
      "Feature: 6, Score: 0.07180\n",
      "Feature: 7, Score: 0.13186\n",
      "Feature: 8, Score: 0.04485\n",
      "Feature: 9, Score: 0.08066\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vi kan se att vår model har använt sig främst av feature \n",
    "# 1, 3, 4, 7 och 9, och vi kan därför gissa att dessa är våra\n",
    "# informativa features. \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Print the feature perfomance prettier\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a model from the best features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_fs:  (700, 5) X_train:  (700, 10)\n",
      "X_test_fs:  (300, 5) X_test:  (300, 10)\n"
     ]
    }
   ],
   "source": [
    "# Vi vill nu ta bort de features som inte är informativa,\n",
    "# vi kan göra detta genom att använda oss av SelectFromModel\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Write a function that selects the most important features\n",
    "\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # Find a good subset of features\n",
    "\n",
    "    fs = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold=0.08)\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    print(\"X_train_fs: \", X_train_fs.shape, \"X_train: \", X_train.shape)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    print(\"X_test_fs: \", X_test_fs.shape, \"X_test: \", X_test.shape)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# Run the function\n",
    "\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "# Vi kan nu se att vi har fått ut 3 features som är de mest informativa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       144\n",
      "           1       0.93      0.90      0.92       156\n",
      "\n",
      "    accuracy                           0.91       300\n",
      "   macro avg       0.91      0.91      0.91       300\n",
      "weighted avg       0.91      0.91      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Träna en modell med de nya featuresen\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_fs, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test_fs)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       144\n",
      "           1       0.95      0.93      0.94       156\n",
      "\n",
      "    accuracy                           0.94       300\n",
      "   macro avg       0.94      0.94      0.94       300\n",
      "weighted avg       0.94      0.94      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vi kan skapa en modell som jämför de 3 featuresen med de alla 10 featuresen\n",
    "\n",
    "rf_all_features = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_all_features.fit(X_train, y_train)\n",
    "\n",
    "y_pred_all_features = rf_all_features.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "\n",
    "print(classification_report(y_test, y_pred_all_features))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
